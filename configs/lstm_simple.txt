#LSTM CONFIG SIMPLE
n=5
# Normalization types: sample, term, sample_then_term. Any other value disables normalization
normalize_by=sample
lstm_normalization_multiplier=1
# Algorithm Specific Parameters
# If you specify embedding_enabled=true, then you will add an embedding layer to the start of the LSTM.
# Normalization works poorly with embedding.
embedding_enabled=true
embedding_level=32
LSTM_depth=512
num_layers=2
# Denselayer. Since we want a binary output it is set to one.
denselayer_size=1
dropout=0.1
# Training settings.
epochs=20
batch_size=32
# Regularization
l2_regularization=false
regularization_weight=0.0001
# Univariate Feature Selection filter type. "percent" for top ufs_number% features. "count" for top ufs_number features.
ufs_type=percent
ufs_number=100
# ufs_stage specifices when the ufs should take place. For the entire dataset prior to execution: "pre". For each training set during cross validation: "kfold". "none" for disabling UFS.
ufs_stage=none
# Default tf.keras.layers.LSTM(
#    units, activation='tanh', recurrent_activation='sigmoid',
#    use_bias=True, kernel_initializer='glorot_uniform',
#    recurrent_initializer='orthogonal',
#    bias_initializer='zeros', unit_forget_bias=True,
#    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,
#    activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,
#    bias_constraint=None, dropout=0.0, recurrent_dropout=0.0,
#    return_sequences=False, return_state=False, go_backwards=False, stateful=False,
#    time_major=False, unroll=False, **kwargs
#)
# Other parameters passed to programme are required, but do not have default values.